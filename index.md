## ABOUT ME
**Seasoned Software Engineer and Analyst** with experience working on a range of **Full-Stack Data Science** projects, and expertise in **Data-Engineering, Server-Side (small to mid-scale web applications), Applied-Statistics** and **Machine-Learning**. Have demonstrated **resiliency**, **drive to innovate**, and **ability to adapt** to different technology stacks and leverage them to build robust web and data products. Accustomed to working effectively with highly **cross-functional teams**. 

## MY EXPERIENCE

- ### Cyncly | Sr Data Engineer (Oct 2023 – June 2024)  

  - #### Computer-Vision/AI Features | Interior Design Software (Python, MongoDB, Azure Synapse, Service Bus, FastAPI/Flask, Data Lake, Vertex AI):
    As the **newly formed A.I. Center of Excellence's first data engineer**, I got to **influence the team's strategic direction for its data operations** as well as **envision** and **implement foundational pipelines**, with guidance from the team's Senior Architect, and in the process make hiring decisions to expand the team as well.    

    - Collaborated with AI teams to design data-models for a **vector database**, **optimized for read-operations** as needed by dependent REST APIs, while simultaneously contributing to the implementation of relevant APIs. 

    - Ideated and implemented an on-demand, idempotent batch data pipeline, hosted on **Azure Synapse**, empowering downstream teams with a **self-serve tool**, **reducing time** of **data acquisition and rationalization** by **90%**. 

    - Implemented **logging modules** for convenient monitoring of highly **complex data-transformation procedures**, along with proposing incorporation of **event-sourcing pattern** into existing workflows for supporting debugging efforts. 


- ### Amazon | Analytics (Business-Intelligence) Engineer (June 2021 – Oct 2023) | Selected Work 

  - #### Workforce Analytics (AWS-Lambda, Python, QuickSight, Pub-Sub (SNS-SQS), AWS Firehose, Redshift/Athena, PySpark, AWS Glue, AWS Step Functions, AWS S3): 
    Built multiple data-ingestion (real-time) and analytics workflows for customers at Amazon Science. The KPIs generated enabled ML-Engineers to **gauge quality of human-annotated images’ data**, used for **training Computer Vision** models, deployed at **Amazon’s Robotics Fulfilment centers**. 

    - As a critical step in training production grade ML models, I **implemented pipelines and workflows**, to **enable** an intricate **multi-stage process** for **auditing** of **human annotations** on image-data by respective Ops managers, to **minimise** occurrences of **discrepant annotations**. Further, I created requisite datasets with important fields generated by the workflows, enabling required insights generation. 

    - **Put contingency plans** in place to respond to **production issues** in a time-effective manner. Took initiatives to implement mechanisms to mitigate or **fix data-quality** problems **improving time-to-resolution** of bugs by **roughly 50%**. 

    - Worked on effective **partitioning strategies** within different **data-lake zones** and explored **query prioritization features** using query and user groups on redshift to **improve response times**.  

    - Developed **readable and re-usable** code modules, inculcating **relevant design principles**, and leveraged **event-driven architectural patterns** to create **idempotent and fault-tolerant pipelines** with well-planned **logging and alerts** in place.  

    - Proposed and ran experiments for an ML use-case to use image-annotations' meta-data to **predict the time taken for annotating each image (takt)** by a particular associate. Experimented with **robust-regression models** (handling outliers), and devised/implemented methods to **track takt deviations** for new production jobs based on error between predicted and actual.
   

  - #### Tool to Review Org Reporting Structure (DynamoDB, AWS-Lambda, Python, GraphQL):
    Developed server-side procedures/code for a small-scale tool, to implement logic leveraging **tree-traversal** methods to navigate and enforce user made alterations in the org-structure: **hierarchical-data stored in JSON** format as items in **DynamoDb**. Considered multiple options and made trade-offs in terms of how to make the updates and persist the updated data in DynamoDb.


- ### Tredence Analytics Solutions Pvt. Ltd. |Software Engineer (June 2018 – July 2020) | Senior Software Engineer (July 2020 – June 2021) | Selected Work 

  - #### Large Scale Machine-Learning/Demand-forecasting|(ExpressJS, MS-SQL, ORM/Sequelize, PySpark/Spark-SQL, fbprophet, Azure Databricks):
    Worked in a highly **cross-functional team** to deliver an end-to-end analytics solution which processed **large volumes of batch-data** to provide **insights into product sales** of a multinational consumer goods and personal care corporation.
    
      - **Co-designed and implemented** a **demand-forecasting/ML pipeline using PySpark** in Azure Databricks to periodically generate constrained and unconstrained demand forecasts.
        
      - Worked with clients to define/implement methods to identify different inventory problems (eg. Out of Stock, Phantom Inventory) and **calculate daily historical/future lost sales (~ several millions of dollars)** due to each for various products across thousands of stores.
        
      - Implemented and optimized read-intensive RESTful services and data-models using ExpressJS and MS-SQL to enable features like multi-tenancy and embedding of tenant specific power-BI dashboard views in the client-side ReactJS application.
   
      - Monitored **API response-times using Apache JMeter under concurrent loads** and improved the same to remain within SLA parameters by incorporating simple caching where needed.     

  - #### Digital Customer Experience Platform (Flask/Python/MySQL/Google-Cloud-Platform/OAuth-SSO/Microservices):
    A **digital customer experience platform** - a suite of web applications (Flask/Django) - to track customer journey and engage with them via different channels at various touchpoints. The efforts were aimed at enhancing customer satisfaction and minimizing churn.

      - **Implemented various Flask RESTful services**, and made significant contributions to an existing large code base, to add a language translation-request tracking workflow to an **application** that enabled users to **create customer-specific email templates**. The translation-requests were processed by external services integrated with REST APIs. Also implemented automated statistical significance testing modules to measure **effectiveness of content** (by **measuring click-through rates**).
   
      - Under the guidance of a lead data-scientist, worked on a **churn-modelling** ML project. Explored **techniques for feature engineering (temporal features)** and handling **data imbalance** (SMOTE). Experimented with different ensemble models. Implemented critical procedures using Python and delivered a final solution that helped the customers **identify strong indicators of potential churn**.
   
- ## SELECTED SIDE PROJECTS:
  -  [Json Object Navigator](https://pypi.org/project/navigate-json/): Developers often work with extremely **complex JSON** data and end up spending a lot of manual effort to inspect and develop code to access data nested deep in the JSON structure. Built a Python API that automatically **generates the code** and hence **saves manual efforts**.
 
  - Similar Content Based Image Search Application (Flask/Tensorflow/PyTorch/Redis-Queue/Docker/jQuery/Jinja): Developed a Flask application where users can upload  images and discover images with similar content from Google search based on image contents. Used **pre-trained object detection** as well as **image captioning** models. Used **redis-queue** to create **background tasks for inference**.
 
  - Recommendation System API (Python/PyTorch): A python API that can be used to **simulate online user interaction** driven by different **recommendation algorithms** (MABT) and check effectiveness of the algorithms against each other using **relevant statistical significance tests**. Also wrote an implementation of ALS (Alternating Least Squares) with NumPy. Working on integrating ability to perform collaborative filtering on user interaction data.
 
- ## MY SKILLS AND DOMAIN KNOWLEDGE:
  - Programming: Python, NodeJS, MySQL. Familiar with Java/C++. Have an idea of ReactJS and Bootstrap 5. Familiar with various data structures, algorithms, OOP concepts.
 
  - ML/AI/Statistical techniques: Statistical significance tests, PCA/Factor Analysis, Regression/classification models, Clustering, CV: object detection,segmentation etc., NLP, Reinforcement Learning etc.
    
  - Tech Stack and Tools: Have worked on Flask, ExpressJS, AWS Redshift, PySpark, AWS S3, SNS-SQS, Azure, Google Cloud Platform, Scikit-Learn, Scipy, PyTorch, Tensorflow, Redis Queue.
    
  - Courses/Certifications: Deep Neural Networks with PyTorch
 
- ## ACADEMICS:
  B-Tech: Electrical and Electronics Engineering. | VIT VELLORE | 2014-18 

- ## ACCOMPLISHMENTS:
  Power Squad Award for impact on one of Tredence’s client’s digital customer experience solutions. 

 
  
      








